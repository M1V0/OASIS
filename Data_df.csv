ID,Title,Authors,Abstract,Date Published,DOI,URL
3yx2r_v1,Perceptual judgements are resistant to the advisor's perceived level of trustworthiness: a deep fake approach,"Mathias Van der Biest, Sam Verschooren, Frederick Verbruggen, Marcel Brass","As we navigate our environment, we often make spontaneous judgments about others. Trustworthiness is a key characteristic that we judge instantly and then use when making decisions, especially when we are uncertain. While the effect of trustworthiness on social behaviour has been extensively investigated, it remains unclear how trustworthiness affects more ‘basic’ cognitive processes such as perceptual decision-making. The present study aims to fill this gap. In the first experiment (N = 100), we validated a new trustworthiness manipulation by using deep fake technology to create animated versions of perceptually trustworthy, untrustworthy, and neutral static computer-generated faces. In the second experiment (N = 199), the deep fake procedure was applied to a new set of trustworthy and untrustworthy faces that served as advisors during a perceptual decision-making task. Here participants had to indicate the direction of dots that were either moving coherently to the left or to the right (i.e., random dot motion task). Contrary to our predictions, participants did not follow the advice of the trustworthy advisors more often than the advice of the untrustworthy advisors. We did find that participants decided faster and were more confident when following the advice, but this was also not influenced by the trustworthiness of the advisors. We integrate our findings within theoretical frameworks of advice taking, domain specificity of facial trustworthiness, and task requirements.",2024-05-09T12:35:09.876570,,https://osf.io/preprints/psyarxiv/3yx2r_v1/
hwujb_v1,"Individual Deep Fake Recognition Skills are Affected by Viewers’ Political Orientation, Agreement with Content and Device Used","Stefan Sütterlin, Torvald F. Ask, Sophia Mägerle, Sandra Glöckler, Leandra Wolf, Julian Schray, Alaya Chandi, Teodora Bursac, Ali Khodabakhsh, Benjamin J. Knox","AI-generated “deep fakes” are becoming increasingly professional and can be expected to become an essential tool for cybercriminals conducting targeted and tailored social engineering attacks, as well as for others aiming for influencing public opinion in a more general sense. While the technological arms race is resulting in increasingly efficient forensic detection tools, these are unlikely to be in place and applied by common users on an everyday basis any time soon, especially if social engineering attacks are camouflaged as unsuspicious conversations. To date, most cybercriminals do not yet have the necessary resources, competencies or the required raw material featuring the target to produce perfect impersonifications. To raise awareness and efficiently train individuals in recognizing the most widespread deep fakes, the understanding of what may cause individual differences in the ability to recognize them can be central. Previous research suggested a close relationship between political attitudes and top-down perceptual and subsequent cognitive processing styles. In this study, we aimed to investigate the impact of political attitudes and agreement with the political message content on the individual’s deep fake recognition skills.
In this study, 163 adults (72 females = 44.2%) judged a series of video clips with politicians’ statements across the political spectrum regarding their authenticity and their agreement with the message that was transported. Half of the presented videos were fabricated via lip-sync technology. In addition to the particular agreement to each statement made, more global political attitudes towards social and economic topics were assessed via the Social and Economic Conservatism Scale (SECS).
Data analysis revealed robust negative associations between participants’ general and in particular social conservatism and their ability to recognize fabricated videos. This effect was pronounced where there was a specific agreement with the message content. Deep fakes watched on mobile phones and tablets were considerably less likely to be recognized as such compared to when watched on stationary computers.
To the best of our knowledge, this study is the first to investigate and establish the association between political attitudes and interindividual differences in deep fake recognition. The study further supports very recently published research suggesting relationships between conservatism and perceived credibility of conspiracy theories and fake news in general. Implications for further research on psychological mechanisms underlying this effect are discussed.",2021-12-30T14:24:35.177365,10.1007/978-3-031-35017-7_18,https://osf.io/preprints/psyarxiv/hwujb_v1/

ID,Title,Abstract,Date Published,Tags,DOI,URL,Contributors,Provider
E0169-DC7-EB6,Perceptual judgements are resistant to the advisor's perceived level of trustworthiness: a deep fake approach,"As we navigate our environment, we often make spontaneous judgments about others. Trustworthiness is a key characteristic that we judge instantly and then use when making decisions, especially when we are uncertain. While the effect of trustworthiness on social behaviour has been extensively investigated, it remains unclear how trustworthiness affects more ‘basic’ cognitive processes such as perceptual decision-making. The present study aims to fill this gap. In the first experiment (N = 100), we validated a new trustworthiness manipulation by using deep fake technology to create animated versions of perceptually trustworthy, untrustworthy, and neutral static computer-generated faces. In the second experiment (N = 199), the deep fake procedure was applied to a new set of trustworthy and untrustworthy faces that served as advisors during a perceptual decision-making task. Here participants had to indicate the direction of dots that were either moving coherently to the left or to the right (i.e., random dot motion task). Contrary to our predictions, participants did not follow the advice of the trustworthy advisors more often than the advice of the untrustworthy advisors. We did find that participants decided faster and were more confident when following the advice, but this was also not influenced by the trustworthiness of the advisors. We integrate our findings within theoretical frameworks of advice taking, domain specificity of facial trustworthiness, and task requirements.",2024-05-09T12:35:09.876570+00:00,"deep fake,faces,social cognition,trustworthiness,advice taking,perceptual decision making",,,"Sam Verschooren, Marcel Brass, Mathias Van der Biest, Frederick Verbruggen",psyarxiv
E0153-ACC-2E6,Are we overclaiming the Psychosocial Impacts of Misinformation? A Systematic Review of Evidence,"Misinformation, or what we call ‘Technologically manipulated information’ (TMI), has a long history of shaping people's social lives. Research in this area has spiked recently, especially after the COVID-19 pandemic. With technological advancement, the ease of manipulating information, as in ‘deep fake,’ and its quick dissemination over social media has caused a stir among researchers. ’ However, in the relevant literature, a general assumption is repeatedly observed that misinformation and TMI lead to negative psychosocial impacts. The present review systematically analyzes the empirical evidence available in the research literature for the negative impact of misinformation. The aim is to gather proof for this commonly held belief about the impact and identify the gaps in the literature, if any.",2023-07-06T03:45:14.343020+00:00,"misinformation,ai,social networking sites,covid 19,psychosocial impact,and deepfakes",,,Ankita Sharma,psyarxiv
E01D3-B7B-DB4,"Individual Deep Fake Recognition Skills are Affected by Viewers’ Political Orientation, Agreement with Content and Device Used","AI-generated “deep fakes” are becoming increasingly professional and can be expected to become an essential tool for cybercriminals conducting targeted and tailored social engineering attacks, as well as for others aiming for influencing public opinion in a more general sense. While the technological arms race is resulting in increasingly efficient forensic detection tools, these are unlikely to be in place and applied by common users on an everyday basis any time soon, especially if social engineering attacks are camouflaged as unsuspicious conversations. To date, most cybercriminals do not yet have the necessary resources, competencies or the required raw material featuring the target to produce perfect impersonifications. To raise awareness and efficiently train individuals in recognizing the most widespread deep fakes, the understanding of what may cause individual differences in the ability to recognize them can be central. Previous research suggested a close relationship between political attitudes and top-down perceptual and subsequent cognitive processing styles. In this study, we aimed to investigate the impact of political attitudes and agreement with the political message content on the individual’s deep fake recognition skills. In this study, 163 adults (72 females = 44.2%) judged a series of video clips with politicians’ statements across the political spectrum regarding their authenticity and their agreement with the message that was transported. Half of the presented videos were fabricated via lip-sync technology. In addition to the particular agreement to each statement made, more global political attitudes towards social and economic topics were assessed via the Social and Economic Conservatism Scale (SECS). Data analysis revealed robust negative associations between participants’ general and in particular social conservatism and their ability to recognize fabricated videos. This effect was pronounced where there was a specific agreement with the message content. Deep fakes watched on mobile phones and tablets were considerably less likely to be recognized as such compared to when watched on stationary computers. To the best of our knowledge, this study is the first to investigate and establish the association between political attitudes and interindividual differences in deep fake recognition. The study further supports very recently published research suggesting relationships between conservatism and perceived credibility of conspiracy theories and fake news in general. Implications for further research on psychological mechanisms underlying this effect are discussed.",2021-12-30T14:24:35.177365+00:00,"fake news,deepfakes,conservatism,deep fakes,recognition,political orientation,cybercrime,perception,social media,social engineering",,,"Matthew Canham, Leandra Wolf, Torvald F. Ask, Teodora Bursac, Stefan Sütterlin, Julian Schray, Sandra Glöckler, Ali Khodabakhsh, Alaya Chandi, Sophia Mägerle, Benjamin J. Knox, Ricardo Lugo",psyarxiv
